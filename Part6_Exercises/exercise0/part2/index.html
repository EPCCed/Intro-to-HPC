<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Part 2: Compiling and running Hello world! &mdash; Introduction to HPC (Beta)  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_lesson.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/term_role_formatting.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_rtd_theme_ext_color_contrast.css" />

  
    <link rel="shortcut icon" href="../../../_static/epcc_logo.svg"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/minipres.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../../../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="Practical exercise 1: First use of HPC machine, Image sharpening code" href="../../exercise1/" />
    <link rel="prev" title="Part 1: Logging in via SSH" href="../part1/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            Introduction to HPC (Beta)
              <img src="../../../_static/epcc_logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../Part0_Introduction/contents/">Introduction to High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Part1_Supercomputing/contents/">Supercomputing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Part2_Parallel_Computers/contents/">Parallel Computers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Part3_Parallel_Computing/contents/">Parallel Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Part4_Computer_Simulations/contents/">Computer Simulations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../contents/">Exercises</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../">Practical exercise 0: First use of HPC machine, Hello World!</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../part1/">Part 1: Logging in via SSH</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Part 2: Compiling and running Hello world!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#serial">Serial</a></li>
<li class="toctree-l4"><a class="reference internal" href="#threading">Threading</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mpi">MPI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hybrid">Hybrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../exercise1/">Practical exercise 1: First use of HPC machine, Image sharpening code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../exercise2/">Practical exercise 2: Parallel worksharing, Fractal code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../exercise3/">Pratical exercise 3: Investigating parallel performance, GROMACS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../exercise4/">Practical exercise 4: Traffic simulation</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">Introduction to HPC (Beta)</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../contents/">Exercises</a></li>
          <li class="breadcrumb-item"><a href="../">Practical exercise 0: First use of HPC machine, Hello World!</a></li>
      <li class="breadcrumb-item active">Part 2: Compiling and running Hello world!</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/EPCCed/Intro-to-HPC/blob/master/content/Part6_Exercises/exercise0/part2.md" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="part-2-compiling-and-running-hello-world">
<h1>Part 2: Compiling and running Hello world!<a class="headerlink" href="#part-2-compiling-and-running-hello-world" title="Permalink to this heading"></a></h1>
<p>This example is meant to get you used to the command line environment of a high performance computer and submitting jobs to the batch system, while learning about the hardware of a HPC system.</p>
<p>In the following we are going to look at variety of hello world programs and look at the two most common types of parallelism in the HPC world.</p>
<p>One that takes advantage of shared memory and one that uses distributed memory in a HPC system. We will then look at how they can be combined but first we start with a simple serial code.</p>
<section id="serial">
<h2>Serial<a class="headerlink" href="#serial" title="Permalink to this heading"></a></h2>
<p>The serial example runs a job on a node with a single process. This is the same as if you ran on your local machine.</p>
<p>For those who are interested the code we are executing is,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;stdlib.h&gt;</span>
<span class="c1">#include &lt;unistd.h&gt;</span>
<span class="c1">#include &lt;limits.h&gt;</span>
<span class="c1">#include &lt;string.h&gt;</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>

    <span class="o">//</span> <span class="n">Check</span> <span class="nb">input</span> <span class="n">argument</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Required one argument `name`.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Receive</span> <span class="n">argument</span>

    <span class="n">char</span><span class="o">*</span> <span class="n">iname</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]));</span>

    <span class="n">strcpy</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

    <span class="o">//</span> <span class="n">Get</span> <span class="n">the</span> <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">node</span> <span class="n">we</span> <span class="n">are</span> <span class="n">running</span> <span class="n">on</span>

    <span class="n">char</span> <span class="n">hostname</span><span class="p">[</span><span class="n">HOST_NAME_MAX</span><span class="p">];</span>
    <span class="n">gethostname</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span> <span class="n">HOST_NAME_MAX</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Hello</span> <span class="n">World</span> <span class="n">message</span>

    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello World!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">the</span> <span class="n">node</span> <span class="n">to</span> <span class="n">the</span> <span class="n">user</span>

    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello </span><span class="si">%s</span><span class="s2">, this is </span><span class="si">%s</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">iname</span><span class="p">,</span> <span class="n">hostname</span><span class="p">);</span>

<span class="p">}</span>

</pre></div>
</div>
<p>This is a simple C code but it will say hello to you and report which node it is running from.</p>
<p>To try this example yourself you will first need to compile the example code.</p>
<p>If the file that contains the above code is called <code class="docutils literal notranslate"><span class="pre">helloWorldSerial.c</span></code> then to compile on ARCHER2 use command,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cc</span> <span class="n">helloWorldSerial</span><span class="o">.</span><span class="n">c</span> <span class="o">-</span><span class="n">o</span> <span class="n">hello</span><span class="o">-</span><span class="n">SER</span>
</pre></div>
</div>
<p>To run this example using the compute nodes via the job queue, use the following bash script written for ARCHER2,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
#!/bin/bash

#SBATCH --job-name=Hello-SER
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=00:01:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --partition=standard
#SBATCH --qos=standard

# Set the number of threads to the CPUs per task
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

NODES=$SLURM_JOB_NUM_NODES
CORES=$((NODES*128))
THREADS=$OMP_NUM_THREADS

export OMP_PLACES=cores

echo &quot;job start&quot;

# Launch the parallel job
srun --hint=nomultithread --distribution=block:block ./hello-SER YOUR_NAME_HERE &gt; SERIAL-${NODES}nodes-${CORES}cores-${THREADS}threads.${SLURM_JOBID}.out

echo &quot;job complete&quot;

</pre></div>
</div>
<p>Place this bash code into a a file called <code class="docutils literal notranslate"><span class="pre">Hello_Serial_Slurm.sh</span></code> in the same directory as the previous code and replace <code class="docutils literal notranslate"><span class="pre">YOUR_NAME_HERE</span></code> with your own input.</p>
<p>To submit this job run,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="n">Hello_Serial_Slurm</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>This should return two files as output,</p>
<ul class="simple">
<li><p>The first file name begins with <code class="docutils literal notranslate"><span class="pre">SERIAL-...</span></code> is the log file from the job and contains a message produced by the code at run time.</p></li>
<li><p>The second file name begins with <code class="docutils literal notranslate"><span class="pre">slurm</span></code> is the output from the script used to submit the job.</p></li>
</ul>
<p>Have a look in both files and identify the source of the different messages.</p>
<p>This example is small enough that it can be run on the login nodes of ARCHER2 by running,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">hello</span><span class="o">-</span><span class="n">SER</span>
</pre></div>
</div>
<p>How does this differ from when you run using the batch script?</p>
</section>
<hr class="docutils" />
<section id="threading">
<h2>Threading<a class="headerlink" href="#threading" title="Permalink to this heading"></a></h2>
<p>This threaded example runs on as many threads on a node as you allow it to.</p>
<p>The code is a little more complex than the last example in order to run multiple copies of the response from a number of threads on the node we use OpenMP to parallelise the code.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="c1">#include &lt;omp.h&gt;</span>
<span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;stdlib.h&gt;</span>
<span class="c1">#include &lt;unistd.h&gt;</span>
<span class="c1">#include &lt;limits.h&gt;</span>
<span class="c1">#include &lt;string.h&gt;</span>


<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>

  <span class="o">//</span> <span class="n">Check</span> <span class="nb">input</span> <span class="n">argument</span>

  <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span>
  <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Required one argumnet `name`.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
      <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="o">//</span> <span class="n">Receive</span> <span class="n">argument</span>

  <span class="n">char</span><span class="o">*</span> <span class="n">iname</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]));</span>

  <span class="n">strcpy</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

  <span class="o">//</span> <span class="n">Get</span> <span class="n">the</span> <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">node</span> <span class="n">we</span> <span class="n">are</span> <span class="n">running</span> <span class="n">on</span>

  <span class="n">char</span> <span class="n">hostname</span><span class="p">[</span><span class="n">HOST_NAME_MAX</span><span class="p">];</span>
  <span class="n">gethostname</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span> <span class="n">HOST_NAME_MAX</span><span class="p">);</span>

  <span class="o">//</span> <span class="n">Hello</span> <span class="n">World</span> <span class="n">message</span>

  <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello World!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>

  <span class="o">//</span> <span class="n">Message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">each</span> <span class="n">thread</span> <span class="n">on</span> <span class="n">the</span> <span class="n">node</span> <span class="n">to</span> <span class="n">the</span> <span class="n">user</span>

  <span class="c1">#pragma omp parallel</span>
  <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello </span><span class="si">%s</span><span class="s2">, this is node </span><span class="si">%s</span><span class="s2"> responding from thread </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">iname</span><span class="p">,</span> <span class="n">hostname</span><span class="p">,</span>
           <span class="n">omp_get_thread_num</span><span class="p">());</span>
  <span class="p">}</span>

<span class="p">}</span>

</pre></div>
</div>
<p>To try this example yourself you will first need to compile the example code.</p>
<p>If the file that contains the above code is called <code class="docutils literal notranslate"><span class="pre">helloWorldThreaded.c</span></code> then to compile on ARCHER2 use command,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">cc</span> <span class="n">helloWorldThreaded</span><span class="o">.</span><span class="n">c</span> <span class="o">-</span><span class="n">fopenmp</span> <span class="o">-</span><span class="n">o</span> <span class="n">hello</span><span class="o">-</span><span class="n">THRD</span>

</pre></div>
</div>
<p>Where <code class="docutils literal notranslate"><span class="pre">-fopenmp</span></code> is a flag that tells the compiler that we are using openmp a library that allows up to write threaded code.</p>
<p>In order to run this on a ARCHER2 node we can use the following script,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
#!/bin/bash

#SBATCH --job-name=Hello-THRD
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --time=00:01:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --partition=standard
#SBATCH --qos=standard

# Set the number of threads to the CPUs per task
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

NODES=$SLURM_JOB_NUM_NODES
CORES=$((NODES*128))
THREADS=$OMP_NUM_THREADS

export OMP_PLACES=cores

echo &quot;job start&quot;

# Launch the parallel job
srun --hint=nomultithread --distribution=block:block ./hello-THRD YOUR_NAME_HERE THREADED-${NODES}nodes-${CORES}cores-${THREADS}threads.${SLURM_JOBID}.out

echo &quot;job complete&quot;

</pre></div>
</div>
<p>Place this bash code into a a file called <code class="docutils literal notranslate"><span class="pre">Hello_Thread_Slurm.sh</span></code> in the same directory as the previous code and replace <code class="docutils literal notranslate"><span class="pre">YOUR_NAME_HERE</span></code> with your own input.</p>
<p>To submit this job run,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="n">Hello_Thread_Slurm</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>This should return two files as output,</p>
<ul class="simple">
<li><p>The first file name begins with <code class="docutils literal notranslate"><span class="pre">THREADED-...</span></code> is the log file from the job and contains a message produced by the code at run time. Notice how in this case each thread has sent a message.</p></li>
<li><p>The second file name begins with <code class="docutils literal notranslate"><span class="pre">slurm</span></code> is the output from the script used to submit the job.</p></li>
</ul>
<p>Have a look in both files and try to identify the source of the different messages.</p>
<p>As in the serial case we have run a single process but now the process runs a number of threads. Threaded codes can take advantage of the shared memory aspect of a HPC systems to pass data between each thread but cannot communicated between distinct nodes.</p>
<p>If you run this code on multiple processes then it will still work but without MPI communication these processes will be entirely independent and are not able to communicate information.</p>
</section>
<hr class="docutils" />
<section id="mpi">
<h2>MPI<a class="headerlink" href="#mpi" title="Permalink to this heading"></a></h2>
<p>MPI is a message passing interface, this allow for messages to be sent by multiple instances of the program running on different nodes to each other. Each instance of the program is controlled by a separate instance of the operating system.</p>
<p>This MPI example each process says hello in the programs and states which node it is running on and which process in the group it is.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;mpi.h&gt;</span>
<span class="c1">#include &lt;iostream&gt;</span>
<span class="c1">#include &lt;string.h&gt;</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="o">//</span> <span class="n">Check</span> <span class="nb">input</span> <span class="n">argument</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Required one argument `name`.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Receive</span> <span class="n">arguments</span>

    <span class="n">char</span><span class="o">*</span> <span class="n">iname</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">char</span><span class="o">*</span> <span class="n">iname2</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>

    <span class="n">strcpy</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="n">strcpy</span><span class="p">(</span><span class="n">iname2</span><span class="p">,</span> <span class="n">iname</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">MPI</span> <span class="n">Setup</span>

    <span class="nb">int</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="nb">len</span><span class="p">;</span>
    <span class="n">char</span> <span class="n">name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>

    <span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="nb">len</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Create</span> <span class="n">message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">rank</span> <span class="mi">0</span> <span class="n">to</span> <span class="n">broadcast</span> <span class="n">to</span> <span class="nb">all</span> <span class="n">processes</span><span class="o">.</span>

    <span class="n">strcat</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span> <span class="s2">&quot;@&quot;</span><span class="p">);</span>
    <span class="n">strcat</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>

    <span class="nb">int</span> <span class="n">inameSize</span> <span class="o">=</span> <span class="n">strlen</span><span class="p">(</span><span class="n">iname</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Create</span> <span class="n">buffer</span> <span class="k">for</span> <span class="n">message</span>

    <span class="n">char</span><span class="o">*</span> <span class="n">buff</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">inameSize</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Sending</span> <span class="n">process</span> <span class="n">fills</span> <span class="n">the</span> <span class="n">buffer</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="n">strcpy</span><span class="p">(</span><span class="n">buff</span><span class="p">,</span> <span class="n">iname</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Send</span> <span class="n">the</span> <span class="n">message</span>
    
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">buff</span><span class="p">,</span> <span class="n">inameSize</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Send</span> <span class="n">different</span> <span class="n">messages</span> <span class="kn">from</span><span class="w"> </span><span class="nn">different</span> <span class="n">ranks</span>

    <span class="o">//</span> <span class="n">Send</span> <span class="n">hello</span> <span class="kn">from</span><span class="w"> </span><span class="nn">rank</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world, my name is </span><span class="si">%s</span><span class="s2">, I am sending this message from process </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> total processes executing, which is running on node </span><span class="si">%s</span><span class="s2">. </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">iname2</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Send</span> <span class="n">responce</span> <span class="kn">from</span><span class="w"> </span><span class="nn">the</span> <span class="n">other</span> <span class="n">ranks</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello, </span><span class="si">%s</span><span class="s2"> I am process </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> total processes executing and I am running on node </span><span class="si">%s</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">buff</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span>

</pre></div>
</div>
<p>To try this example yourself you will first need to compile the example code.</p>
<p>If the file that contains the above code is called <code class="docutils literal notranslate"><span class="pre">helloWorldMPI.c</span></code> then to compile on ARCHER2 use command,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cc</span> <span class="n">helloWorldMPI</span><span class="o">.</span><span class="n">c</span> <span class="o">-</span><span class="n">o</span> <span class="n">hello</span><span class="o">-</span><span class="n">MPI</span>
</pre></div>
</div>
<p>We can run this executable using this bash script,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
#!/bin/bash

#SBATCH --job-name=Hello-MPI
#SBATCH --nodes=4
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=00:20:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --partition=standard
#SBATCH --qos=standard

# Set the number of threads to the CPUs per task
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

NODES=$SLURM_JOB_NUM_NODES
CORES=$((NODES*128))
THREADS=$OMP_NUM_THREADS

export OMP_PLACES=cores

echo &quot;job start&quot;

# Launch the parallel job
srun --hint=nomultithread --distribution=block:block ./hello-MPI YOUR-NAME-HERE &gt; MPI-${NODES}nodes-${CORES}cores-${THREADS}threads.${SLURM_JOBID}.out

echo &quot;job complete&quot;

</pre></div>
</div>
<p>Place this bash code into a a file called <code class="docutils literal notranslate"><span class="pre">Hello_MPI_Slurm.sh</span></code> in the same directory as the previous code and replace <code class="docutils literal notranslate"><span class="pre">YOUR_NAME_HERE</span></code> with your own input.</p>
<p>To submit this job run,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="n">Hello_MPI_Slurm</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>This should return two files as output,</p>
<ul class="simple">
<li><p>The first file name begins with <code class="docutils literal notranslate"><span class="pre">MPI-...</span></code> is the log file from the job and contains a message produced by the code at run time.</p></li>
<li><p>The second file name begins with <code class="docutils literal notranslate"><span class="pre">slurm</span></code> is the output from the script used to submit the job.</p></li>
</ul>
<p>In the above script we assume one process per node this means we see one process per node responding to our welcome.</p>
<p>Example output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Hello</span> <span class="n">world</span><span class="p">,</span> <span class="n">my</span> <span class="n">name</span> <span class="ow">is</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="p">,</span> <span class="n">I</span> <span class="n">am</span> <span class="n">sending</span> <span class="n">this</span> <span class="n">message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">process</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span><span class="p">,</span> <span class="n">which</span> <span class="ow">is</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001059</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001059</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001060</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001059</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">2</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001069</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001059</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">3</span> <span class="n">of</span> <span class="mi">4</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001098</span><span class="o">.</span>
</pre></div>
</div>
<p>We can however have multiple processes per node, if we update our bash script to,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
#!/bin/bash

#SBATCH --job-name=Hello-MPI
#SBATCH --nodes=2
#SBATCH --tasks-per-node=4
#SBATCH --cpus-per-task=1
#SBATCH --time=00:20:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --partition=standard
#SBATCH --qos=standard

# Set the number of threads to the CPUs per task
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

NODES=$SLURM_JOB_NUM_NODES
CORES=$((NODES*128))
THREADS=$OMP_NUM_THREADS

export OMP_PLACES=cores

echo &quot;job start&quot;

# Launch the parallel job
srun --hint=nomultithread --distribution=block:block ./hello-MPI YOUR-NAME-HERE &gt; MPI-${NODES}nodes-${CORES}cores-${THREADS}threads.${SLURM_JOBID}.out

echo &quot;job complete&quot;

</pre></div>
</div>
<p>In this updated script we have increased the number of processes per node. This means we see multiple processes respond per node.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Hello</span> <span class="n">world</span><span class="p">,</span> <span class="n">my</span> <span class="n">name</span> <span class="ow">is</span> <span class="n">yourname</span><span class="p">,</span> <span class="n">I</span> <span class="n">am</span> <span class="n">sending</span> <span class="n">this</span> <span class="n">message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">process</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span><span class="p">,</span> <span class="n">which</span> <span class="ow">is</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001452</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001452</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">2</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001452</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">3</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001452</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">4</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001453</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">5</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001453</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">6</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001453</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001452</span> <span class="n">I</span> <span class="n">am</span> <span class="n">process</span> <span class="mi">7</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001453</span><span class="o">.</span>
</pre></div>
</div>
</section>
<section id="hybrid">
<h2>Hybrid<a class="headerlink" href="#hybrid" title="Permalink to this heading"></a></h2>
<p>This hybrid code has all the process respond to an initial message from process 0. As this is a hybrid code each of the threads in each process respond with a message.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;mpi.h&gt;</span>
<span class="c1">#include &lt;omp.h&gt;</span>
<span class="c1">#include &lt;iostream&gt;</span>
<span class="c1">#include &lt;string.h&gt;</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="o">//</span> <span class="n">Check</span> <span class="nb">input</span> <span class="n">argument</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Required one argument `name`.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Receive</span> <span class="n">arguments</span>

    <span class="n">char</span><span class="o">*</span> <span class="n">iname</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">char</span><span class="o">*</span> <span class="n">iname2</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">strlen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>

    <span class="n">strcpy</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="n">strcpy</span><span class="p">(</span><span class="n">iname2</span><span class="p">,</span> <span class="n">iname</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">MPI</span> <span class="n">Setup</span>

    <span class="nb">int</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="nb">len</span><span class="p">;</span>
    <span class="n">char</span> <span class="n">name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>

    <span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="nb">len</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Create</span> <span class="n">message</span> <span class="n">to</span> <span class="n">broadcast</span> <span class="n">to</span> <span class="nb">all</span> <span class="n">processes</span><span class="o">.</span>

    <span class="n">strcat</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span> <span class="s2">&quot;@&quot;</span><span class="p">);</span>
    <span class="n">strcat</span><span class="p">(</span><span class="n">iname</span><span class="p">,</span><span class="n">name</span><span class="p">);</span>

    <span class="nb">int</span> <span class="n">inameSize</span> <span class="o">=</span> <span class="n">strlen</span><span class="p">(</span><span class="n">iname</span><span class="p">);</span>

    <span class="o">//</span> <span class="n">Create</span> <span class="n">buffer</span> <span class="k">for</span> <span class="n">message</span>

    <span class="n">char</span><span class="o">*</span> <span class="n">buff</span> <span class="o">=</span> <span class="p">(</span><span class="n">char</span> <span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">inameSize</span><span class="p">);</span>


    <span class="o">//</span> <span class="n">Sending</span> <span class="n">process</span> <span class="n">fills</span> <span class="n">the</span> <span class="n">buffer</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="n">strcpy</span><span class="p">(</span><span class="n">buff</span><span class="p">,</span> <span class="n">iname</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="o">//</span> <span class="n">Send</span> <span class="n">the</span> <span class="n">message</span>

    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">buff</span><span class="p">,</span> <span class="n">inameSize</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world, my name is </span><span class="si">%s</span><span class="s2">, I am sending this message from process </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> total processes executing, which is running on node </span><span class="si">%s</span><span class="s2">. </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">iname2</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="c1">#pragma omp parallel</span>
      <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello, </span><span class="si">%s</span><span class="s2"> I am thread </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> threads in process </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> total processes executing and I am running on node </span><span class="si">%s</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">buff</span><span class="p">,</span> <span class="n">omp_get_thread_num</span><span class="p">(),</span> <span class="n">omp_get_num_threads</span><span class="p">(),</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span>
</pre></div>
</div>
<p>The bash script to run this for ARCHER2 ,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
#!/bin/bash

# Slurm job options (name, compute nodes, job time)
#SBATCH --job-name=Hello-HYB
#SBATCH --time=00:20:00
#SBATCH --nodes=4
#SBATCH --tasks-per-node=2
#SBATCH --cpus-per-task=2

# Replace [budget code] below with your budget code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --qos=standard
#SBATCH --partition=standard

# Set the number of threads to the CPUs per task
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

NODES=$SLURM_JOB_NUM_NODES
CORES=$((NODES*128))
THREADS=$OMP_NUM_THREADS

export OMP_PLACES=cores

echo &quot;job start&quot;

# Launch the parallel job
srun --hint=nomultithread --distribution=block:block ./hello-HYB YOUR-NAME-HERE &gt; HYBRID-${NODES}nodes-${CORES}cores-${THREADS}threads-run.${SLURM_JOBID}.out

echo &quot;job complete&quot;

</pre></div>
</div>
<p>Place this bash code into a a file called <code class="docutils literal notranslate"><span class="pre">Hello_hybrid_Slurm.sh</span></code> in the same directory as the previous code and replace <code class="docutils literal notranslate"><span class="pre">YOUR_NAME_HERE</span></code> with your own input.</p>
<p>To submit this job run,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="n">Hello_hybrid_Slurm</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>This should return two files as output,</p>
<ul class="simple">
<li><p>The first file name begins with <code class="docutils literal notranslate"><span class="pre">HYBRID-...</span></code> is the log file from the job and contains a message produced by the code at run time.</p></li>
<li><p>The second file name begins with <code class="docutils literal notranslate"><span class="pre">slurm</span></code> is the output from the script used to submit the job.</p></li>
</ul>
<p>In this example has the 0th process sends the a message your-name&#64;nodeId to all the other processes and the print a message in a response.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Hello</span> <span class="n">world</span><span class="p">,</span> <span class="n">my</span> <span class="n">name</span> <span class="ow">is</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="p">,</span> <span class="n">I</span> <span class="n">am</span> <span class="n">sending</span> <span class="n">this</span> <span class="n">message</span> <span class="kn">from</span><span class="w"> </span><span class="nn">process</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span><span class="p">,</span> <span class="n">which</span> <span class="ow">is</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001780</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001780</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">2</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001782</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">3</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001782</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">4</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001783</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">5</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001783</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">6</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001785</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">0</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">7</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001785</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001780</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">2</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001782</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">3</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001782</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">4</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001783</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">5</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001783</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">6</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001785</span><span class="o">.</span>
<span class="n">Hello</span><span class="p">,</span> <span class="n">your</span><span class="o">-</span><span class="n">name</span><span class="nd">@nid001780</span> <span class="n">I</span> <span class="n">am</span> <span class="n">thread</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">2</span> <span class="n">threads</span> <span class="ow">in</span> <span class="n">process</span> <span class="mi">7</span> <span class="n">of</span> <span class="mi">8</span> <span class="n">total</span> <span class="n">processes</span> <span class="n">executing</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="n">running</span> <span class="n">on</span> <span class="n">node</span> <span class="n">nid001785</span><span class="o">.</span>
</pre></div>
</div>
<p>This uses a simple broadcast for this example but it illustrates that a message has been passed to all the other nodes and each thread is able to access the transmitted information and write a custom response.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading"></a></h2>
<p>The point of this exercise was to show that there are different ways to parallelise a program and use the hardware a high performance computer gives you access to. The examples here just report the location of each process and thread however in a more realistic scenario each of these examples are different ways to organise a calculation. We might choose different ways to spread out our calculation based on the memory requirement, processing power and communication strategies that are optimal for a given simulation. Choosing the correct strategy can give performance benefits but potentially at the cost of more complex code.</p>
<p>A few other tests you can try to solidify your knowledge:</p>
<ul class="simple">
<li><p>Run the serial code with more than one process what do you see?</p></li>
<li><p>Running the threaded code with more than one process what do you see?</p></li>
<li><p>running the MPI code on a single node with multiple processes what you you see?</p></li>
</ul>
<p>Remember that message passing codes cost an overhead to send messages and threaded codes cant scale beyond the size of a single node.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../part1/" class="btn btn-neutral float-left" title="Part 1: Logging in via SSH" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../exercise1/" class="btn btn-neutral float-right" title="Practical exercise 1: First use of HPC machine, Image sharpening code" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, EPCC at the University of Edinburgh.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>